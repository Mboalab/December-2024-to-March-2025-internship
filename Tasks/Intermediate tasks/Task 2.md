# Task 2: Data exploration and preprocessing
## Objective:  
Accurate and trustworthy models are built on a foundation of well-organized and clean data. Interns will increase the quality of their analysis and avoid mistakes by seeing and fixing data anomalies, missing values, and inconsistencies. 
Moreover, normalization and feature engineering assist in transforming the data into a format that is appropriate for machine learning algorithms.

Interns will use a variety of skills to complete this assignment. They must possess a thorough understanding of feature engineering, data cleaning, missing value handling, and other preprocessing methods as well as data exploration. Understanding of visualization tools will be crucial for identifying trends and patterns within the data. 

Good resources to get started with:
- [Getting Started with python environments](https://medium.com/analytics-vidhya/getting-started-with-python-anaconda-google-colab-and-virtual-environments-1ce8fc3286f9)

_Note that you do not need to be a master in VCS/Git/GitHub to start contributing. 
Once you are comfortable with the basics, you can start contributing to open-source._

## Main activities to complete: 
- Examine the information gathered about jobs, scholarships, and internships.
- Find and fix any data anomalies, missing values, or inconsistencies.
- Include feature engineering and normalization in your cleaning and preparation of the data for usage in AI models.
- Examine the data and look for trends by using visualization tools.
- Document your task 1, include your notebook

## Adressed to:
>**This task is particularly adressed to Newcomers and all applicants desiring to grasp Machine learning and Artificial Intelligence as well as everyone willing to contribute to this project and getting to know each other.**

## Attributed Mentor:
Attributed mentor to get in touch with for this task is **Petra Ukeh**


